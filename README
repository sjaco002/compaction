MBtree.insert is where we are storing these write times

needKeyDupCheck should be false so we only see the real reads

When connected to ssh, http://localhost:19001 can use the cluster


parameters to set in asterix-configuration.xml:
		buffercachepagesize:131072

		memorycomponentpagesize:131072

		memorycomponent num of pages:256

		HOW MANY in-memroy components per index:1 (default is 2. Set to 1 or 2)

		memory for the buffer cache:3221225472

		bloom filter ratio: .01

Steps to run simulation:
	On bigtable:
		Run everything.sh 
			starts instance by copying in local.xml and asterix-configuration.xml
			Runs startFeed.sh
				creates datasets and feed
				(more exmples in sampleParametersForSetup.txt)
	on dblab-server
		SendTweetsAndSearch.py 
			Sendsthe tweets and updates to search_id
		screen -dm nohup python sendTweets.py	
			Sends just the tweets
	on bigtable
		Run screen -dm nohup bash startKeyQuery.sh > nohup.out
			Runs the  query, pausing for 1 second between runs
		Run cd totals && screen -dm nohup bash ../startCountQuery.sh > nohup.out
			Runs the  total count query every hour
	when complete, on bigtable:
		Run copyFiles.sh
			Greps from the asterix logs and collects results in csv folder
		
